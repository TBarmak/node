{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_Week_7.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rl1uK_MURpS9"
      },
      "source": [
        "# K-Nearest Neighbors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahy6eMBlR32S"
      },
      "source": [
        "Starting off with the usual imports, these should be second nature by now!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt2SPXbfROfQ"
      },
      "source": [
        "#For the dataframe and array manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#For visualization\n",
        "import plotly\n",
        "import plotly.express as px"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUBMInyVR_9J"
      },
      "source": [
        "We'll be starting with a basic example of how KNN works with an automatically generated dataset, so we'll also need the following imports."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJuxtwg6SI_l"
      },
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV8XPaT0Skzu"
      },
      "source": [
        "Sklearn's make_blobs() function is used to generate clustered data based on a variety of parameters; this is perfect for looking at how certain algorithms work.\n",
        "\n",
        "We will also need the KNeighborsClassifier model for our classification task; note that we will need to import from `sklearn.neighbors` rather than `sklearn.tree`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heoSRLoPTjYg"
      },
      "source": [
        "## Create and Visualize The Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS-RtvnGTwBa"
      },
      "source": [
        "To start things off, we'll be creating a dataset with 400 total points clustered into two groups.\n",
        "\n",
        "Using make_blobs(), we can also set the number of features each data point will have. We'll set the number of features to 2 so we can plot the features easily."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TslO-wVYTYyM"
      },
      "source": [
        "points, labels = make_blobs(n_samples=400, centers=2, n_features=2,\n",
        "                            cluster_std=.5, center_box=(-4,4), random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwU6q3OcUhKQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOduouUfUtKo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww2-TYpfWVx-"
      },
      "source": [
        "We now already have the data split into X and y sets, which is perfect for the training step.\n",
        "\n",
        "However, we may want to create a dataframe from these numpy arrays to be able to visualize what the data actually looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqhxVY3BWn3Y"
      },
      "source": [
        "data = pd.DataFrame(points, columns=[\"feature_1\",\"feature_2\"])\n",
        "data['target'] = labels.astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP_NAsqWWvqq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fKj6dIWXnTQ"
      },
      "source": [
        "Now, lets create a scatter plot with each feature on a seperate axis.\n",
        "\n",
        "Each point will have a color corresponding to its target value, the value that we want to predict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuSz0R8VWwjg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYidDakGbA10"
      },
      "source": [
        "As can be seen in the plot, our data is nicely split into two distinct clusters. Because of this, we can make a pretty reasonable guess about the target value of a new point.\n",
        "\n",
        "Let's train the model and see if it matches our intuition. Since we're only predicting a single point at a time, we'll train the model on the entire dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9CMPqqdxh75"
      },
      "source": [
        "## Fit and Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0ZDdhNBcXJQ"
      },
      "source": [
        "X = data.drop(columns=[\"target\"])\n",
        "y = data[\"target\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw-T9xL9OWof"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohpFmpwrpR8J"
      },
      "source": [
        "Now let's predict three distinct points and see what the model decides to output.\n",
        "\n",
        "1. (2, 2.5)\n",
        "2. (0, 5)\n",
        "3. (0.3, 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz4P9u9yldv-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVbTaja-puSa"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "LABEL_COLOR_MAP = {0:'r',1:'b'}\n",
        "label_color = [LABEL_COLOR_MAP[l] for l in labels]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtN05XczngjO"
      },
      "source": [
        "plt.scatter(x=data['feature_1'],y=data['feature_2'],c=label_color)\n",
        "plt.xlabel('feature_1')\n",
        "plt.ylabel('feature_2')\n",
        "plt.scatter(x=2,y=2.5,marker=\"x\",c=\"g\",s=100)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Pkbht-Koh_6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6zBXrFDoFde"
      },
      "source": [
        "plt.scatter(x=data['feature_1'],y=data['feature_2'],c=label_color)\n",
        "plt.xlabel('feature_1')\n",
        "plt.ylabel('feature_2')\n",
        "plt.scatter(x=0,y=5,marker=\"x\",c=\"g\",s=100)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrJhiieYok9-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo73L5f7oM-E"
      },
      "source": [
        "plt.scatter(x=data['feature_1'],y=data['feature_2'],c=label_color)\n",
        "plt.xlabel('feature_1')\n",
        "plt.ylabel('feature_2')\n",
        "plt.scatter(x=0.3,y=2,marker=\"x\",c=\"g\",s=100)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Pm_YeBAlwbd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USoDZEKapJRP"
      },
      "source": [
        "Success! Each of the predictions matched our intuition!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BETCaDjPp-Vd"
      },
      "source": [
        "# KNN on Real World Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQnG6oGCqNn2"
      },
      "source": [
        "We tested the algorithm on a small, artificial dataset with only 2 features, but how well does it perform on real world data with potentially many features?\n",
        "\n",
        "We will be using the breast cancer dataset once again to hopefully find an answer to this question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_90QqwBxqj5J"
      },
      "source": [
        "## Loading and Preprocessing the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPo_BJqopesI"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/ishaandey/node/master/week-7/workshop/breast_cancer.csv'\n",
        "df  = pd.read_csv(url)\n",
        "\n",
        "\n",
        "df = df.drop(columns=['id','Unnamed: 32'])\n",
        "df['diagnosis'] = df['diagnosis'].map({'M':1,'B':0})\n",
        "\n",
        "\n",
        "X = df.drop(columns=['diagnosis'])\n",
        "y = df['diagnosis']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItpH-lhftaih"
      },
      "source": [
        "## Fitting the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is756gJCtc4Q"
      },
      "source": [
        "clf = KNeighborsClassifier()\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iuu6nuUt_VK"
      },
      "source": [
        "By default, the KNeighborsClassifier uses a value of K=5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On0OlKJUtlKO"
      },
      "source": [
        "predicted = clf.predict(X_test)\n",
        "actual = np.array(y_test)\n",
        "\n",
        "print('Look at first 10 predictions:')\n",
        "print('Predicted: ',predicted[:10])\n",
        "print('Actual:    ',actual[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcBi1UjPtyn9"
      },
      "source": [
        "k5 = accuracy_score(predicted,actual)\n",
        "print(k5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1RdOgkuuO4b"
      },
      "source": [
        "Looks like the default classifier gave a pretty decent score. However, we need to note that accuracy is not a great metric for determining model performance and the score itself is relative.\n",
        "\n",
        "This is still lower than the score gleaned by the Random Forest model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKJoYHPFtSPF"
      },
      "source": [
        "## What value of K?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQmj7PV4ujal"
      },
      "source": [
        "While the default classifier was decent, we can also adjust the number of neighbors that the model looks at to get potentially better results. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiQ5a1MAvs49"
      },
      "source": [
        "k_values = [1,5,10,50,200]\n",
        "scores = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiG7srg2vX6G"
      },
      "source": [
        "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
        "clf1.fit(X_train, y_train)\n",
        "predicted = clf1.predict(X_test)\n",
        "actual = np.array(y_test)\n",
        "k1 = accuracy_score(predicted,actual)\n",
        "scores.append(k1)\n",
        "scores.append(k5)\n",
        "print(k1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G85G_j7gtXal"
      },
      "source": [
        "clf10 = KNeighborsClassifier(n_neighbors=10)\n",
        "clf10.fit(X_train, y_train)\n",
        "predicted = clf10.predict(X_test)\n",
        "actual = np.array(y_test)\n",
        "k10 = accuracy_score(predicted,actual)\n",
        "scores.append(k10)\n",
        "print(k10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i86aeHgRvQy4"
      },
      "source": [
        "clf50 = KNeighborsClassifier(n_neighbors=50)\n",
        "clf50.fit(X_train, y_train)\n",
        "predicted = clf50.predict(X_test)\n",
        "actual = np.array(y_test)\n",
        "k50 = accuracy_score(predicted,actual)\n",
        "scores.append(k50)\n",
        "print(k50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqOEEIn6vLxs"
      },
      "source": [
        "clf200 = KNeighborsClassifier(n_neighbors=200)\n",
        "clf200.fit(X_train, y_train)\n",
        "predicted = clf200.predict(X_test)\n",
        "actual = np.array(y_test)\n",
        "k200 = accuracy_score(predicted,actual)\n",
        "scores.append(k200)\n",
        "print(k200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9rj0TISwELQ"
      },
      "source": [
        "plt.plot(k_values,scores,'go--', linewidth=2, markersize=12)\n",
        "plt.xlabel('Number of Neighbors')\n",
        "plt.ylabel('Accuracy of Model')\n",
        "plt.title('K value versus Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9XEs3RExCHi"
      },
      "source": [
        "As we can see, adding more neighbors does not equate to higher model accuracy. Each dataset is unique, and we need to select a value for K based on the nuances in the data to get the best performance from our KNN model.\n",
        "\n",
        "For this particular dataset, a K value of 10 (look for the 10 nearest datapoints) gave us the best results on the unknown data."
      ]
    }
  ]
}