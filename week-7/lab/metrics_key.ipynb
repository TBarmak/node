{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week7lab_key.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IGOkh4T9xug"
      },
      "source": [
        "# **Classification Metrics: Tools (Aside from Accuracy) for Assessing ML Models**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9ET4NkS4Jj9"
      },
      "source": [
        "# Import the following packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Numpy random seed for consistency\n",
        "np.set_printoptions(precision=4, suppress=True)\n",
        "np.random.seed(123) #use this random \"seed\" so that we can all get the same synthetic data!\n",
        "\n",
        "# To model normal distribution\n",
        "from scipy.stats import norm\n",
        "\n",
        "# To make data\n",
        "from sklearn.datasets import make_blobs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40fMDGy2-fyv"
      },
      "source": [
        "## Let's begin by making synthetic data with 2 features (to be used for classification as a 1 or 0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_APxI1Et4TDk"
      },
      "source": [
        "#Make data set with 3000 observations\n",
        "n = 3000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "N1Cl2nZ84YqX",
        "outputId": "73d4c0df-0fb9-4e3f-fed3-5ea1d0333bac"
      },
      "source": [
        "centers = [[9.5, 0], [10.5, 0]] # Define the coordinates to center our blobs (x,y)\n",
        "X, y = make_blobs(n_samples=n, centers=centers, cluster_std=0.4, random_state=7)\n",
        "data = pd.DataFrame(X, columns=['feature1','feature2']) # Rename the feature columns (like x and y; coordinates to be used to classify points as 0 or 1)\n",
        "data['target'] = y.astype('str') # Convert dtype to help w/ viz\n",
        "\n",
        "data.head() #view the first few rows "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9.607937</td>\n",
              "      <td>-0.002729</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10.229965</td>\n",
              "      <td>0.054297</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10.269156</td>\n",
              "      <td>0.044818</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.418941</td>\n",
              "      <td>-0.042682</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.422457</td>\n",
              "      <td>0.278918</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    feature1  feature2 target\n",
              "0   9.607937 -0.002729      0\n",
              "1  10.229965  0.054297      1\n",
              "2  10.269156  0.044818      0\n",
              "3  10.418941 -0.042682      1\n",
              "4   9.422457  0.278918      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lmZyIQb4jH-",
        "outputId": "4045bb12-fc94-46f0-fed5-a31ae1f9135b"
      },
      "source": [
        "#View the shape of our synthetic data, and the frequencies of each class (Hint: value_counts())\n",
        "print('Shape:', data.shape, '\\n')\n",
        "print('Class Frequencies:')\n",
        "print(data.target.value_counts(normalize=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape: (3000, 3) \n",
            "\n",
            "Class Frequencies:\n",
            "1    0.5\n",
            "0    0.5\n",
            "Name: target, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ESS5qEy_Cf7"
      },
      "source": [
        "As you can see, the \"class frequencies\" of 0 and 1 observations depict a 50-50 split, meaning that half of our data is 1's and half of our data is 0's"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbArmS4__hKy"
      },
      "source": [
        "**Below is a pre-made classifier (common classifiers we have/may learn are regression, Decision Trees, K Nearest Neighbors, etc.). This classifier will make the predictions of 0's and 1's based upon training and testing data **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8K2G0jB470f"
      },
      "source": [
        "class BoundaryClassifier():\n",
        "    def __init__(self):\n",
        "        from scipy.stats import norm\n",
        "        self.name = 'Classify observations on 1D boundary'\n",
        "    \n",
        "    def fit(self, X_train, y_train, x_boundary=None):\n",
        "        self.boundary = x_boundary\n",
        "        \n",
        "    def predict(self, X_test):\n",
        "        b = self.boundary\n",
        "        x = X_test.feature1\n",
        "        y_pred =  (x > b).astype(np.int) #boundary, b, a threshold we can use to determine if observation is a 0 or a 1\n",
        "        return y_pred\n",
        "    \n",
        "    def predict_proba(self, X_test): #the predicted probability\n",
        "        b = self.boundary\n",
        "        x = X_test.feature1\n",
        "        \n",
        "        # Use the normal distribution to model probabilities\n",
        "        y_pred_proba = ((x-b)/0.4).apply(norm.cdf)\n",
        "        return y_pred_proba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiW_M-byAmvT"
      },
      "source": [
        "**1. As learned, split your data into training and testing data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZtttuZL5AoS"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = data.drop(columns=['target'])\n",
        "y = data.target.astype('int')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udp7o23oAwgq"
      },
      "source": [
        "**2.Employ the Classifier \"BoundaryClassifier()\" to fit the model to the data and predict the 0 and 1 classes. Hint: an extra input is needed in clf.fit(), called x_boundary. Set this boundary/threshold=10, which is the threshold we can use to determine if a point is a 0 or 1 (threshold determined for this specific synthetic dataset)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwxNIgKE5FHC"
      },
      "source": [
        "clf = BoundaryClassifier() # Create the model\n",
        "clf.fit(X_train, y_train, x_boundary = 10) # Fit it to the dta\n",
        "\n",
        "y_pred = clf.predict(X_test) # Predict classes\n",
        "y_pred_proba = clf.predict_proba(X_test) # Predict the probability of falling into class 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMqfgMfTBgBq"
      },
      "source": [
        "**3.Create a data frame to view the actual class, predicted class (from model), and predicted probability ('y_pred_proba'), from BoundaryClassifier()**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "D_d4WFnc5J-K",
        "outputId": "ca400107-669c-4d6a-cc00-8b4f0545fe57"
      },
      "source": [
        "test_results = pd.DataFrame(data = {'Actual Class':y_test, 'Predicted Class':y_pred, 'Predicted Probabilty':y_pred_proba})\n",
        "test_results.sample(5)\n",
        "#note how when the \"Predicted Probability\" <0.5, you often see actual class != predicted class."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual Class</th>\n",
              "      <th>Predicted Class</th>\n",
              "      <th>Predicted Probabilty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.737880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2659</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.196321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>691</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.024315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.713100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1569</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.992458</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Actual Class  Predicted Class  Predicted Probabilty\n",
              "57               1                1              0.737880\n",
              "2659             1                0              0.196321\n",
              "691              0                0              0.024315\n",
              "102              1                1              0.713100\n",
              "1569             1                1              0.992458"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0l9HuA5CNIh"
      },
      "source": [
        "## **Classification Metrics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh7atiV5CZ7v"
      },
      "source": [
        "1. Compute the accuracy of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f4D_kOC5Q_F",
        "outputId": "15af3bb3-0227-48ad-f1e5-d489d4b614ca"
      },
      "source": [
        "##ACCURACY SCORE\n",
        "from sklearn.metrics import accuracy_score\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "acc.round(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9008"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrrIiRAdCi0e"
      },
      "source": [
        "2. Create a confusion matrix to model the true positives, true negatives, false positives, and false negatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcIwOi8S5VGL",
        "outputId": "f67f0654-f948-4261-9926-fea2ef29dd8c"
      },
      "source": [
        "##CONFUSION MATRIX\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[538  63]\n",
            " [ 56 543]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO7Qlu4j5bX7"
      },
      "source": [
        "#code to turn outputted matrix into a dataframe\n",
        "def custom_confusion_matrix(y_test_, y_pred_proba_, alpha=0.5, output='dataframe'):\n",
        "    \"\"\"\n",
        "    Usage:\n",
        "        cm = custom_confusion_matrix(y_test, y_pred_proba, output = 'dataframe')\n",
        "        tn, fp, fn, tp = custom_confusion_matrix(y_test, y_pred_proba, output = 'rates')\n",
        "\n",
        "    Params:\n",
        "        alpha: Threshold probability for classification (default = 0.5)\n",
        "        output: One of 'dataframe', 'rates', or 'array'\n",
        "    \"\"\"\n",
        "    y_pred_ = (y_pred_proba_ >  alpha).map({True:1,False:0})\n",
        "    cf_mat_ = confusion_matrix(y_test_, y_pred_)\n",
        "    if output == 'dataframe':\n",
        "        return pd.DataFrame(cf_mat_, columns=['Predicted 0', 'Predicted 1'], index=['Actual 0', 'Actual 1'])\n",
        "    elif output == 'rates':\n",
        "        return cf_mat_.ravel()\n",
        "    else:\n",
        "        return cf_mat_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "UjUEE8Nt5cVO",
        "outputId": "ab709f3a-8e47-4f47-9bec-19a4fc927c84"
      },
      "source": [
        "cm = custom_confusion_matrix(y_test, y_pred_proba, output = 'dataframe')\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted 0</th>\n",
              "      <th>Predicted 1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Actual 0</th>\n",
              "      <td>538</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual 1</th>\n",
              "      <td>56</td>\n",
              "      <td>543</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Predicted 0  Predicted 1\n",
              "Actual 0          538           63\n",
              "Actual 1           56          543"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYDJzLix5gHZ",
        "outputId": "44edad27-7b7b-43c8-c62f-64c615587872"
      },
      "source": [
        "#assigning values to corresponding tn, fp, fn, tp measures\n",
        "tn, fp, fn, tp = custom_confusion_matrix(y_test, y_pred_proba, output = 'rates')\n",
        "tn, fp, fn, tp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(538, 63, 56, 543)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j9nS1fgEGkQ"
      },
      "source": [
        "3. Compute the Sensitivity, Specificity, Precision, and F-1 Scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1DwLHO05jWC",
        "outputId": "6edef07b-7d97-4fe1-d366-45bbeab13b76"
      },
      "source": [
        "##SENSITIVITY\n",
        "tpr  = tp / (tp + fn)\n",
        "tpr.round(4)\n",
        "#(543)/(56+543) does the same"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9065"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMlB7mzc5oRU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3c9b02e-4ba6-4666-a713-b7b684ecdf15"
      },
      "source": [
        "##SPECIFICITY\n",
        "tnr=tn/(tn+fp)\n",
        "tnr.round(4)\n",
        "#538/(538+63) does the same"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8952"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBY1xmsc5qBm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8c283dd-901f-410a-f133-312918134578"
      },
      "source": [
        "##PRECISION\n",
        "precision=(tp/(tp+fp))\n",
        "precision.round(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.896"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOdcOTFk5vzv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e1d1162-606a-4f7f-90ab-4ac1a2a201fc"
      },
      "source": [
        "##F-1 SCORE\n",
        "f_1=2*tpr*precision/(tpr+precision) #recall that f_1 is 2*sensitivity*precision/(sensitivity+precision)\n",
        "f_1.round(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9012"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usFg0ZBzENc-"
      },
      "source": [
        "# What does each of these metrics mean in context of the classes in this model?\n",
        "1. Accuracy: how often the classification (1's or 0's overall irrespective of specific class) is made correctly\n",
        "2. Sensitivity: \"true positive rate\"; out of all the actual 1's, how many did the model correctly classify as 1's?\n",
        "3. Specificity: \"true negative rate\"; out of all the actual 0's, how many did the model correctly classify as 0's?\n",
        "4. Precision: out of all the model-predicted 1's, how often was it correct?\n",
        "5. F-1 Score: how well can the model predict 1's ('positive values') and disciminate against 0's ('negative values')?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M98_dptTF0Gv"
      },
      "source": [
        "You can now start to see how important these other classification metrics can be in real-life scenarios. In healthcare, for example, if 1 (positive values) corresponds to the presence of a condition, the *Sensitivity* metric is especially important, because you'd want to maximize the true positive rate of predictions! (\"sensitivity\"=out of all actual disease cases present, how many the model correctly predicted as being present)"
      ]
    }
  ]
}