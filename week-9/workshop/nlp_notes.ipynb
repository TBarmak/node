{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfciZ-hjcPKm"
   },
   "source": [
    "# Natural Language Processing\n",
    "So far, we have focused on data science involving quantitative and categorical variables. Today, we will learn how to analyze bodies of text with Natural Language Processing (NLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOCNLlvX0oBS"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download nltk libraries\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CnX80Th-0ukM"
   },
   "outputs": [],
   "source": [
    "# Read in the IMDB Dataset and look at the first few rows\n",
    "url = 'https://raw.githubusercontent.com/ishaandey/node/master/week-9/workshop/IMDB.csv'\n",
    "reviews = pd.read_csv(url)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BW1pL4d3cngl"
   },
   "source": [
    "In its raw form, the data has one feature (review) and a label (sentiment). Each row is a movie review that is either positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgZZMuYseDw2"
   },
   "source": [
    "As a review (ba dum tsss), let's start by creating our own feature: the length of the review in characters. We're going to use an apply function on the 'review' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qdJnvVPXdUmX"
   },
   "outputs": [],
   "source": [
    "# Create a 'length' column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4Ue_JsSepJd"
   },
   "source": [
    "Let's find the longest review (in terms of number of characters) and use that to learn some NLP skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hEbXUbwkex0y"
   },
   "outputs": [],
   "source": [
    "# Use idxmax to find the index of the longest review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P1QD0MvXe_dW"
   },
   "outputs": [],
   "source": [
    "# Store the text of the longest review\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEmHdDIpW_Wz"
   },
   "source": [
    "Let's lowercase all the words so it's easier to identify words with different capitalizations as the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0qtCa3FCW-_J"
   },
   "outputs": [],
   "source": [
    "# Lowercase txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKb6LS2xZ40m"
   },
   "source": [
    "# Tokenize\n",
    "\"Tokenizing\" is breaking a piece of text into smaller parts. The smaller parts of text are called \"tokens.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ima8EITbfWd"
   },
   "outputs": [],
   "source": [
    "# Import sent_tokenize and word_tokenize from nltk.tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "arCoRkMOfvph"
   },
   "outputs": [],
   "source": [
    "# Tokenize by sentence\n",
    "\n",
    "\n",
    "# See how many sentences are in the review and preview the first 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iXqOmQx4gdE2"
   },
   "outputs": [],
   "source": [
    "# Tokenize by word\n",
    "\n",
    "\n",
    "# See how many words are in the review and preview the first 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSy4hLbKhMtT"
   },
   "source": [
    "Tokenizing by word gives a list of all the words in the text. This allows us to get value counts of all of the words to get a sense of the main ideas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hzTKvAMYgx0l"
   },
   "outputs": [],
   "source": [
    "# Covert to pd.Series and look at the value counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAfiKcrmhYNA"
   },
   "source": [
    "Hmmmm. That's not very helpful. We don't really care about words like \"the,\" \"and,\" and \"to.\" And, punctuation doesn't convey anything. Luckily, there's a really easy way to improve on this!\n",
    "\n",
    "We'll start by removing the punctuation using *punctuation* from the \"string\" library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FrWJR-NTlHHe"
   },
   "outputs": [],
   "source": [
    "# Remove punctuation with for loop (string.punctuation)\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIEv0oAMh922"
   },
   "source": [
    "# Stop Words\n",
    "A stop word is a commonly used word that does not convey much meaning.\n",
    "\n",
    "Let's take a look at the stop words that nltk provides for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ArNExfBjh_Ng"
   },
   "outputs": [],
   "source": [
    "# Take a look at the nltk stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFhaLvoRi-sa"
   },
   "source": [
    "Let's remove these from our tokenized text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gUKZETvPjGD8"
   },
   "outputs": [],
   "source": [
    "# Remove stop words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfZVK6y2nxcw"
   },
   "source": [
    "We can see that 'and' was removed because it is a stop word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VZWTTpiOW1Y5"
   },
   "outputs": [],
   "source": [
    "# Get value counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZ5bQS2tXSIJ"
   },
   "source": [
    "That's more like it! We're getting a sense of the important words in the text. We can still do better though!\n",
    "\n",
    "If \"sneak\" is in the text, we would want to group it with \"sneaking\" because they express the same concept. We can do this with stemming!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IN88rsWWZ7hV"
   },
   "source": [
    "# Stemming\n",
    "Stemming is reducing words to there stem. Words like \"start,\" \"started,\" \"starting,\" and \"starts\" all have the same stem. After stemming them, they will all become \"start.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lWjW0j3rXq7v"
   },
   "outputs": [],
   "source": [
    "# Look at words 15-30 before stemming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tHfRCw_Mpj_n"
   },
   "outputs": [],
   "source": [
    "# Import the PorterStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "# Stem all words in filtered_txt\n",
    "\n",
    "\n",
    "# Compare the previous output with the same words after stemming\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BfTUB8OQYH4h"
   },
   "source": [
    "We can see that \"according\" has been shortened to \"accord.\" \"Started\" has been stemmed to \"start.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oc_w8TaZp178"
   },
   "outputs": [],
   "source": [
    "# Look at the value counts of stemmed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjhW5ECNYyFh"
   },
   "source": [
    "This gives us a much clearer picture of the important concepts in the text. However, we can see that it isn't perfect. Using computers to process text rarely is. The \"'s\" isn't helpful. And interestingly \"booker\" did not get stemmed to \"book.\" The natural language libraries do the best they can, but the English language is complicated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fg3r2QEAY3F6"
   },
   "source": [
    "# Part of Speech Tagging\n",
    "Another cool feature of nltk is POS tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZM_0ZFPZj7K"
   },
   "outputs": [],
   "source": [
    "# Do POS tagging on no_punc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtgxscqgaG1f"
   },
   "source": [
    "NN means singluar nown. CD is a cardinal digit. CC is a coordinating conjuction.\n",
    "\n",
    "Here you can find a description of what the acronyms mean: https://www.guru99.com/pos-tagging-chunking-nltk.html#:~:text=POS%20Tagging%20in%20NLTK%20is%20a%20process%20to,grammatical%20information%20of%20each%20word%20of%20the%20sentence.\n",
    "\n",
    "POS tagging comes in handy for chunking. \"Chunking\" is grouping similar words or phrases together based on the nature of the word or phrase. You can search for sequence of words of different types. For example you could find verbs followed by nouns to get more information on the actions in the text. It involves regular expressions, which we have not covered yet. If NLP is something that interests you, \"chunking\" is definitely something to look into."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eELD8C5sbJwJ"
   },
   "source": [
    "# Sentiment Analysis\n",
    "Sentiment analysis is using computers to categorize opinions in text, especially to determine whether the attitude of the text is positive, negative, or neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dlr0kOpjctEx"
   },
   "outputs": [],
   "source": [
    "# Import TextBlob\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Take a look at the review at index 1\n",
    "\n",
    "\n",
    "# Tokenize by sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t9OqAdwEeA0N"
   },
   "outputs": [],
   "source": [
    "# Get the sentiment of the first sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KivUW1N9dNMs"
   },
   "source": [
    "## Your turn\n",
    "Before having TextBlob tell you the sentiment of the sentences, take a look at the sentences for yourself and decide what you think the sentiment should be.\n",
    "\n",
    "1. Find the polarity and subjectivity of the last sentence in the review we just did. \n",
    "2. Find the polarity and subjectivity of the first sentence (index 0) of the review at index 49996."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9lutvEbx4tpg"
   },
   "outputs": [],
   "source": [
    "# Take a look at the last sentence in positive_sent_tokens and judge the sentiment for yourself\n",
    "# Remember that the index of the last element is \"-1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EpVoOTGBfKMa"
   },
   "outputs": [],
   "source": [
    "# Get the sentiment of the last sentence in review 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X1E9NwtjdMpR"
   },
   "outputs": [],
   "source": [
    "# Get the review at index 49996\n",
    "\n",
    "\n",
    "# Tokenize by sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cyKaEc_J5TMx"
   },
   "outputs": [],
   "source": [
    "# Take a look at the first sentence (index 0) and judge the sentiment for yourself\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDJAGXmJe61U"
   },
   "outputs": [],
   "source": [
    "# Get the sentiment of the first sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmm-VYmSfK6M"
   },
   "source": [
    "As we can see, sentiment analysis works very well for text that is clearly positive or negative. However, in some situations, it can get confused."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sOncoodhe_6"
   },
   "source": [
    "# Bag of Words\n",
    "A bag-of-words is a way of representing text as the frequency of certain words in a text. It involves a vocabulary of known words and a count for each of those words. The bag of words representation ignores the order of the words in the text. It is only concerned with the frequency of each word from the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8JXmowo13JE"
   },
   "outputs": [],
   "source": [
    "# sklearn imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dIPJ35_Shj3w"
   },
   "outputs": [],
   "source": [
    "# Covert the review column to a list of reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_48aFrjph5eh"
   },
   "outputs": [],
   "source": [
    "# Use the CountVectorizer to convert to a BOW representation\n",
    "\n",
    "\n",
    "# Look at the feature names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1oTdwnk6aGn"
   },
   "source": [
    "The features names above are the words in the vocabulary. They were selected because they are the most common words in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q1Y__0fOvIuA"
   },
   "outputs": [],
   "source": [
    "# Take a look at X to see what's going on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U6Z1AmYUvU71"
   },
   "outputs": [],
   "source": [
    "# Convert to a DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R05Ryo2y6mk1"
   },
   "source": [
    "Now we can see the BOW much more clearly. Each row is still a review. But, instead of containing text, there is a column for each word in the vocabulary. Each cell represents the count of that vocabulary word in the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NdHM1Qvvh6Yr"
   },
   "outputs": [],
   "source": [
    "# Map y so that 'positive' is 1 and 'negative' is 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FVBflWeyj1lx"
   },
   "outputs": [],
   "source": [
    "# Train test split\n",
    "# X_train, X_test, y_train, y_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUDRHkH5k_HF"
   },
   "source": [
    "While the cell below is running. It's a good time to talk about the advantages and disadvantages of different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tvKjiQhOjJaN"
   },
   "outputs": [],
   "source": [
    "# Fit a RandomForestClassifier (this takes a little while)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HgO4nQMvjXXE"
   },
   "outputs": [],
   "source": [
    "# Predict on the testing data and compare to the actual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1V3tQR30javH"
   },
   "outputs": [],
   "source": [
    "# Get the accuracy score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seMwotzulQNj"
   },
   "source": [
    "Not bad considering that the reviews are 50% positive and 50% negative!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "nlp_notes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
