{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Documentation:\n",
    "<br>**Description**: Synthetic dataset from Gap Inc., representing a random sample of individual purchases from Q1 FY2020. Each row is a unique item purchased in an order\n",
    "<br><br>\n",
    "\n",
    "| **Feature** | **Description**    | **Sample Value(s)**  |\n",
    "| ------- | -----------    | ------------- |\n",
    "| OrderID | Unique identifier per transaction (7-digit) | DRW7C20   |\n",
    "| CustomerID | Unique identifier per customer (5-digit) | KP441   |\n",
    "| ProductID  | Unique identifier per item (8-digit) | 13-817-239 |\n",
    "| StoreID | Unique identifier per store (4-digit) | #4176 |\n",
    "| OrderType | How purchase was completed  | InStore, HomeDelivery, Online |\n",
    "| Timestamp | Timestamp of transaction (YYYY-MM-DD) | 2020-01-18 10:13:56\t |\n",
    "| Brand | Which reporting segment of Gap Inc. bought from | Banana Republic |\n",
    "| ItemSize | Size of item | XS, S, M, L, X, XL |\n",
    "| ProductName | Name of item associated with item identifier | Pink Polo by Kanye |\n",
    "| Collection | Which part of store | Denim Shop |\n",
    "| Price | Listed price of item | $29.95 |\n",
    "| ClearanceType | Type of clearance | Retail, Clearance, Final Sale |\n",
    "| DiscountType | If Gap Card rewards was used | Reward points, Promotion, GapCash, Other |\n",
    "| StoreName | Store name (i.e. Mall), or facility where online order was shipped from | Fair Oaks Mall |\n",
    "| Location | State of store location | VA |\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some comments about the data**: \n",
    "\n",
    "<br>In the real world, data comes from databases. Each transaction gets recorded as a observation, what item was purchased, at which store, by which customer. We can refer to these items by name, but there can be confusion if there's overlap. (i.e. Two customers with the same name, or two products with the same name)\n",
    "\n",
    "<br>Instead, we can assign **unique identifiers** to each item, store, customer. Even if they have the same name, they'll be distinct in the eyes of the data. Since these are randomly assigned, they can look pretty ugly, but just know that **each ID is associated just one thing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why we're using GroupBys**:\n",
    "\n",
    "<br> Sometimes information in observations can be duplicated. Each row is a item that was purchased by some customer, on some day, at some store. That customer could have purchased *multiple items* in that transaction. To show that, we give each observation from the same transaction the *same OrderID*.\n",
    "\n",
    "<br> This means that if we wanted some information at the transaction level, i.e. how many items were purchased per transaction, we could **first groupby each OrderID**, and then get some summary statistic, i.e 'count' to capture how many items are in each order.\n",
    "\n",
    "<br> Now we have data where each row is a different order. To get the average number of items purchased per transaction, we now **average the grouped data**, and come up with a single number that summarizes that series. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package & Data Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import our usual packages, pandas and numpy. Use pandas to read in the CSV\n",
    "\n",
    "2. Note that we'll have to pass in a new parameter, `sep=|`, to reflect that the raw data is stored a bit differently than usual\n",
    "\n",
    "3. Check out the dimensions of the dataset, then take a look at the dataframe itself.\n",
    "\n",
    "URL = `https://raw.githubusercontent.com/ishaandey/node/master/week-2/lab/gap.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/ishaandey/node/master/week-2/lab/gap.csv', sep='|') # We're using a pipe instead of comma to seperate here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4031, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OrderID</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>StoreID</th>\n",
       "      <th>OrderType</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Brand</th>\n",
       "      <th>ItemSize</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>Collection</th>\n",
       "      <th>Price</th>\n",
       "      <th>ClearanceType</th>\n",
       "      <th>StoreName</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3844</th>\n",
       "      <td>8Q07Q75</td>\n",
       "      <td>UA313</td>\n",
       "      <td>76-558-812</td>\n",
       "      <td>#6658</td>\n",
       "      <td>InStore</td>\n",
       "      <td>2020-03-25 06:10:45</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>M</td>\n",
       "      <td>Yes-I-am-Experiencing-Menopause-Thank-You-for-...</td>\n",
       "      <td>Women's Bottoms</td>\n",
       "      <td>34.95</td>\n",
       "      <td>FullRetail</td>\n",
       "      <td>Stony Point Fashion Park</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>66Z341W</td>\n",
       "      <td>PD193</td>\n",
       "      <td>10-966-490</td>\n",
       "      <td>#9033</td>\n",
       "      <td>HomeDelivery</td>\n",
       "      <td>2020-02-23 22:35:16</td>\n",
       "      <td>Banana Republic</td>\n",
       "      <td>M</td>\n",
       "      <td>Tan Slacks for Serious Press Conference</td>\n",
       "      <td>Men's Bottoms</td>\n",
       "      <td>138.97</td>\n",
       "      <td>FinalSale</td>\n",
       "      <td>Dulles Town Center</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      OrderID CustomerID   ProductID StoreID     OrderType  \\\n",
       "3844  8Q07Q75      UA313  76-558-812   #6658       InStore   \n",
       "343   66Z341W      PD193  10-966-490   #9033  HomeDelivery   \n",
       "\n",
       "                Timestamp            Brand ItemSize  \\\n",
       "3844  2020-03-25 06:10:45  Banana Republic        M   \n",
       "343   2020-02-23 22:35:16  Banana Republic        M   \n",
       "\n",
       "                                            ProductName       Collection  \\\n",
       "3844  Yes-I-am-Experiencing-Menopause-Thank-You-for-...  Women's Bottoms   \n",
       "343             Tan Slacks for Serious Press Conference    Men's Bottoms   \n",
       "\n",
       "       Price ClearanceType                 StoreName Location  \n",
       "3844   34.95    FullRetail  Stony Point Fashion Park       VA  \n",
       "343   138.97     FinalSale        Dulles Town Center       VA  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collection Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions (Easy):\n",
    "Let's take a look at total sales in various collections:\n",
    "1. First, subset down to the *Kids Tops* collection. Grab the price column, then take the sum of that. How much did Kids Tops sales total to?\n",
    "2. What about total sales for the Denim Shop collection? For Accessories? \n",
    "\n",
    "\n",
    "<br>Since it's getting pretty tedious to look for total sales in each collection, let's automate this by taking the sum of sales in each collection. To do so:\n",
    "3. Group the dataframe by Collection, grab the price column, then aggregate the rows by taking a sum across each collection.\n",
    "4. Do your answers here line up with what we found by the subset method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13095.460000000001"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Collection == 'Kids Tops'].Price.sum() #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19796.47"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Collection == 'Denim Shop'].Price.sum() #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6139.860000000001"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Collection == 'Accessories'].Price.sum() #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection\n",
       "Accessories         6139.86\n",
       "Denim Shop         19796.47\n",
       "Kids Bottoms        4746.85\n",
       "Kids Tops          13095.46\n",
       "Men's Bottoms      28907.40\n",
       "Men's Tops         38469.18\n",
       "Women's Bottoms    36413.43\n",
       "Women's Tops       30972.46\n",
       "Name: Price, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Collection').Price.agg('sum') # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13095.460000000014\n",
      "13095.460000000001\n"
     ]
    }
   ],
   "source": [
    "print(sum_by_collection['Kids Tops']) # 4\n",
    "print(kids_tops_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions (Easy):\n",
    "Let's take a look at some product trends:\n",
    "1. How many unique products are there? \n",
    "2. What different collections are there?\n",
    "3. What are top 10 best selling items (in terms of sale frequency)?\n",
    "4. How many times was the `N-A-P Logo Branded Sweater` purchased?\n",
    "<br>\n",
    "\n",
    "#### Tips:\n",
    "Functions you'll probably wanna use: `.unique()`, `.nunique()`, `.value_counts()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ProductName.nunique() # 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Accessories', 'Kids Tops', \"Men's Bottoms\", 'Denim Shop',\n",
       "       \"Men's Tops\", \"Women's Bottoms\", \"Women's Tops\", 'Kids Bottoms'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Collection.unique() # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tan Slacks for Serious Press Conference                  173\n",
       "Acid-Washed Low-Rise Jeans with LSD-tab-sized pockets    172\n",
       "Tan Suit Jacket for Casual Press Conference              150\n",
       "Let's-Wear-White-After-Labor-Day 3/4 Sleeve Blazer       133\n",
       "Sun.png Summer Collection Sundress                       126\n",
       "Name: ProductName, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ProductName.value_counts().head() #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ProductName.value_counts()['N-A-P Logo Branded Sweater']\n",
    "# or\n",
    "len(df[df.ProductName == 'N-A-P Logo Branded Sweater']) #4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions (Easy - Medium):\n",
    "Let's take a look at some breakdowns by business segment, or brand.\n",
    "1. What were *total sales* by brand (in terms of $)?\n",
    "\n",
    "\n",
    "<br>Since a customer can buy multiple items in one transaction, or \"order\", use *OrderID* to prevent double counting.\n",
    "2. What  were the total number of *unique* orders per brand? \n",
    "3. How many orders of each type (`OrderType`) were completed?\n",
    "4. Could we break this down by brand?\n",
    "\n",
    "\n",
    "#### Tips:\n",
    "- First GroupBy, then Aggregate! `.groupby(by=)`, `.agg(func=)`\n",
    "    - Google possible aggregation arguments, like sum, average, or number of unique items\n",
    "- For question 4, use **multi-level groupbys**, i.e. pass a `list` of columns on which to groupby, instead of just one string.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Brand\n",
       "Banana Republic    120011.82\n",
       "Gap                 58529.29\n",
       "Name: Price, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Brand').Price.agg('sum') #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Brand\n",
       "Banana Republic    1349\n",
       "Gap                 823\n",
       "Name: OrderID, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Brand').OrderID.agg('nunique') #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderType\n",
       "HomeDelivery     576\n",
       "InStore         1361\n",
       "StorePickup      235\n",
       "Name: OrderID, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('OrderType').OrderID.agg('nunique') #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderType     Brand          \n",
       "HomeDelivery  Banana Republic    476\n",
       "              Gap                100\n",
       "InStore       Banana Republic    737\n",
       "              Gap                624\n",
       "StorePickup   Banana Republic    136\n",
       "              Gap                 99\n",
       "Name: OrderID, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['OrderType','Brand']).OrderID.agg('nunique') #4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions (Medium):\n",
    "Almost done! Think at the store level:\n",
    "1. Which stores have the lowest sales (in $)? Save its StoreID to a varable, `bad_store`\n",
    "2. How many orders does that store have? (Hint: Use `.index` to capture the key of a pd.Series object)\n",
    "3. What is the maximum number of HomeDelivery orders that any one store got?\n",
    "<br>\n",
    "\n",
    "#### Tips:\n",
    "- We're just chaining things together. Subset, then groupby, then pull a column, then aggregate, then apply a function, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StoreID\n",
       "#1812    4325.72\n",
       "Name: Price, dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1\n",
    "\n",
    "bad_store = df.groupby('StoreID').Price.agg('sum').sort_values(ascending=False).tail(1)\n",
    "bad_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StoreID\n",
       "#1812    68\n",
       "Name: OrderID, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2\n",
    "df.groupby('StoreID').OrderID.agg('nunique')[bad_store.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3\n",
    "df[df.OrderType == 'HomeDelivery'].groupby('StoreID').OrderID.agg('nunique').max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions (Medium - Hard):\n",
    "Let's look at the customers. A couple of questions that management wants us to answer:\n",
    "1. At Gap, how many different stores did each customer shop at, on average? \n",
    "2. On average, how much does each customer spend per transaction? \n",
    "3. Does this value differ when broken down by brand? Which store do customers spend more at?\n",
    "<br>\n",
    "\n",
    "#### Tips:\n",
    "- In general: Think about chaining! Subset, then groupby, then pull a column, then aggregate, then apply a function, etc.\n",
    "- For #1: Since each customer is assigned a unique ID, we wanna get our data at a *per-customer* level. In other words, we'll group by CustomerID first.\n",
    "- For #2: Try to sum up how much *each customer*, at *each order*, spent in total. Then take the average of this.\n",
    "- For #3: Add another level to your previous solution, but then *group* up to the brand level again to consolidate all the customer-orders into each brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4915254237288136"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1\n",
    "df[df.Brand == 'Gap'].groupby('CustomerID').StoreID.agg('nunique').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.20124769797421"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2\n",
    "df.groupby(['CustomerID', 'OrderID']).Price.agg('sum').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Brand\n",
       "Banana Republic    88.963543\n",
       "Gap                71.116999\n",
       "Name: Price, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3\n",
    "df.groupby(['Brand','CustomerID', 'OrderID']).Price.agg('sum').groupby('Brand').mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
